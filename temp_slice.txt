    def _extract_records_from_document(self, document, source_name: str, sheet_name: str, progress_callback=None) -> List[dict[str, str]]:
        """Extract requirement data, headings, text, tables, and images (from paragraphs) from a DOCX file."""
        from docx.table import Table  # type: ignore
        from docx.text.paragraph import Paragraph  # type: ignore

        records: List[dict[str, str]] = []
        front_records: List[Dict[str, str]] = []
        body_started = False

        def add_record(payload: Dict[str, str], *, mark_body: bool = False) -> None:
            nonlocal body_started
            if mark_body and not body_started:
                body_started = True
            records.append(payload)
            if not body_started:
                front_records.append(payload.copy())

        blocks = list(self._iter_doc_blocks(document))
        total_blocks = len(blocks)
        for idx, block in enumerate(blocks, 1):
            if progress_callback and total_blocks > 0:
                percent = int((idx / total_blocks) * 100)
                progress_callback(percent)

            if isinstance(block, Paragraph):
                style_name = (block.style.name or "").lower()

                if self._paragraph_has_image(block):
                    for img_record in self._collect_paragraph_images(block, source_name, sheet_name):
                        add_record(img_record)

                text = block.text.strip()
                if not text:
                    continue

                if self._is_toc_entry(style_name, text):
                    LOGGER.debug("Skipping auto-generated section: %s", text[:60])
                    continue

                obj_type = self._classify_paragraph(style_name)
                req_id, body_text = self._maybe_extract_requirement(text)

                LOGGER.debug("Paragraph: %s", text[:100])
                if req_id:
                    LOGGER.debug("  matched Requirement ID: %s", req_id)

                # Fallback: detect numbered headings like "1 Introduction" or "2.3 Scope"
                # Only treat as heading if it does not look like a TOC entry line
                if not obj_type.startswith("Heading"):
                    if not self._is_toc_entry_line(text):
                        m = re.match(r"^\s*(\d+(?:\.\d+)*)\s+\S", text)
                        if m:
                            depth = 1 + m.group(1).count(".")
                            depth = max(1, min(depth, 3))
                            add_record(
                                {
                                    "Object Type": f"Heading {depth}",
                                    "Requirement ID": "",
                                    "Object Text": text,
                                    "Up Trace": "",
                                    "SourceFile": source_name,
                                    "SheetName": sheet_name,
                                    "SourceType": "docx",
                                    "Attachment Type": "",
                                    "Attachment Data": "",
                                },
                                mark_body=True,
                            )
                            continue

                if req_id and obj_type == "Requirement":
                    add_record({
                        "Object Type": "Requirement",
                        "Requirement ID": req_id,
                        "Object Text": body_text,
                        "Up Trace": "",
                        "SourceFile": source_name,
                        "SheetName": sheet_name,
                        "SourceType": "docx",
                        "Attachment Type": "",
                        "Attachment Data": "",
                    })
                    continue

                if obj_type.startswith("Heading"):
                    add_record({
                        "Object Type": obj_type,
                        "Requirement ID": "",
                        "Object Text": text,
                        "Up Trace": "",
                        "SourceFile": source_name,
                        "SheetName": sheet_name,
                        "SourceType": "docx",
                        "Attachment Type": "",
                        "Attachment Data": "",
                    }, mark_body=True)
                    continue

                add_record({
                    "Object Type": "Text",
                    "Requirement ID": req_id or "",
                    "Object Text": body_text or text,
                    "Up Trace": "",
                    "SourceFile": source_name,
                    "SheetName": sheet_name,
                    "SourceType": "docx",
                    "Attachment Type": "",
                    "Attachment Data": "",
                })
                continue

            if isinstance(block, Table):
                html_table = self._table_to_html(block)
                if not html_table.strip():
                    continue
                add_record({
                    "Object Type": "Table",
                    "Requirement ID": "",
                    "Object Text": "",
                    "Up Trace": "",
                    "SourceFile": source_name,
                    "SheetName": sheet_name,
                    "SourceType": "docx",
                    "Attachment Type": "table",
                    "Attachment Data": html_table,
                })

        self.front_matter_records[source_name] = [copy.deepcopy(r) for r in front_records]

        if not records:
            LOGGER.warning("No paragraphs or tables parsed from %s", source_name)
            return records

        return records

    def _clean_word_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        if df is None or df.empty:
            return pd.DataFrame() if df is None else df.copy()

        work = df.reset_index(drop=True)

        # Remove auto-generated Table of Contents / List of Figures / List of Tables sections
        drop_idx: List[int] = []
        skip_mode: Optional[str] = None
        for idx, row in work.iterrows():
            obj_type = str(row.get("Object Type", "") or "").lower()
            text = str(row.get("Object Text", "") or "").strip()
            if obj_type.startswith("heading"):
                skip_mode = None
                mode = self._is_auto_list_heading(text)
                if mode:
                    skip_mode = mode
                    drop_idx.append(idx)
                continue
            if skip_mode:
                try:
                    is_entry = (
                        (skip_mode == "toc" and self._is_toc_entry_line(text)) or
                        (skip_mode == "lof" and self._is_lof_entry_line(text)) or
                        (skip_mode == "lot" and self._is_lot_entry_line(text))
                    )
                except Exception:
                    is_entry = False
                if is_entry or not text:
                    drop_idx.append(idx)
                    continue
                skip_mode = None

        if drop_idx:
            work = work.drop(drop_idx).reset_index(drop=True)

        if getattr(self, "skip_front_matter_for_word", False) and {"SourceFile", "Object Type"}.issubset(work.columns):
            drop_idx = []
            for _, sub in work.groupby(work["SourceFile"].astype(str), sort=False):
                heading_mask = sub["Object Type"].astype(str).str.lower().str.startswith("heading")
                if not heading_mask.any():
                    # Try numeric heading detection: first row whose Object Text starts with 1 / 1.2 etc.
                    try:
                        nt = sub["Object Text"].astype(str).str.match(r"^\s*\d+(?:\.\d+)*\s+\S")
                        heading_mask = nt
                    except Exception:
                        pass
                if heading_mask.any():
                    first_idx = heading_mask[heading_mask].index[0]
                    drop_idx.extend([i for i in sub.index if i < first_idx])
            if drop_idx:
                work = work.drop(drop_idx).reset_index(drop=True)

        return work

    def get_front_matter_records(self, source_name: str) -> List[Dict[str, str]]:
        records = self.front_matter_records.get(source_name, [])
        return [copy.deepcopy(r) for r in records]

    # ------------------------------------------------------------------
    def _iter_doc_blocks(self, document) -> Iterable[object]:
        """Yield paragraphs and tables in document order."""
        from docx.oxml.text.paragraph import CT_P  # type: ignore
        from docx.oxml.table import CT_Tbl  # type: ignore
        from docx.table import Table  # type: ignore
        from docx.text.paragraph import Paragraph  # type: ignore

        for child in document.element.body.iterchildren():
            if isinstance(child, CT_P):
                yield Paragraph(child, document)
            elif isinstance(child, CT_Tbl):
                yield Table(child, document)

    # ------------------------------------------------------------------
    def _classify_paragraph(self, style_name: str) -> str:
        style_lower = style_name.lower()
        if "heading 1" in style_lower:
            return "Heading 1"
        if "heading 2" in style_lower:
            return "Heading 2"
        if "heading 3" in style_lower:
            return "Heading 3"
        return "Requirement"

    # ------------------------------------------------------------------
    def _paragraph_has_image(self, paragraph) -> bool:
        """Detect inline/floating images, including legacy VML, inside a paragraph."""
        a_ns = "{http://schemas.openxmlformats.org/drawingml/2006/main}"
        vml_ns = "{urn:schemas-microsoft-com:vml}"
        for run in paragraph.runs:
            el = run._element
            if el.findall(f".//{a_ns}blip") or el.findall(f".//{a_ns}drawing"):
                return True
            # Legacy VML image data
            if el.findall(f".//{vml_ns}imagedata"):
                return True
        return False

    # ------------------------------------------------------------------
    def _collect_paragraph_images(self, paragraph, source_name: str, sheet_name: str) -> List[dict[str, str]]:
        """Extract images (inline, floating, or legacy VML) from a paragraph."""
        from docx.oxml.ns import qn  # type: ignore

        records: List[dict[str, str]] = []
        seen: set[str] = set()
        el = None

        for run in paragraph.runs:
            el = run._element
            # DrawingML images
            for blip in el.findall(".//{http://schemas.openxmlformats.org/drawingml/2006/main}blip"):
                rel_id = blip.get(qn("r:embed"))
                if not rel_id or rel_id in seen:
                    continue
                seen.add(rel_id)
                part = paragraph.part.related_parts.get(rel_id)
                if not part:
                    continue
                mime = getattr(part, "content_type", "image/png")
                filename = Path(str(part.partname)).name
                payload = json.dumps({
                    "mime": mime,
                    "data": base64.b64encode(part.blob).decode("ascii"),
                    "filename": filename,
                })
                records.append({
